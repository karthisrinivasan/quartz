<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="Here is the page description. This is an example Quartz site that details installation, setup, customization, and troubleshooting for Quartz itself."><title>Quartz Example Page</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=../../icon.png><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700&family=Source+Sans+Pro:wght@400;700&family=Fira+Code:wght@400;700&display=swap" rel=stylesheet><style>:root{--light:#faf8f8;--dark:#141021;--secondary:#284b63;--tertiary:#84a59d;--visited:#afbfc9;--primary:#f28482;--gray:#4e4e4e;--lightgray:#f0f0f0;--outlinegray:#dadada}[saved-theme=dark]{--light:#1e1e21 !important;--dark:#fbfffe !important;--secondary:#5b778a !important;--visited:#4a575e !important;--tertiary:#84a59d !important;--primary:#f58382 !important;--gray:#d4d4d4 !important;--lightgray:#292633 !important;--outlinegray:#343434 !important}</style><style>:root{--lt-colours-light:var(--light) !important;--lt-colours-lightgray:var(--lightgray) !important;--lt-colours-dark:var(--secondary) !important;--lt-colours-secondary:var(--tertiary) !important;--lt-colours-gray:var(--outlinegray) !important}h1,h2,h3,h4,ol,ul,thead{font-family:Inter;color:var(--dark)}p,ul,text{font-family:source sans pro,sans-serif;color:var(--gray);fill:var(--gray)}a{font-family:Inter;font-weight:700;font-size:1em;text-decoration:none;transition:all .2s ease;color:var(--secondary)}a:hover{color:var(--tertiary)!important}#TableOfContents>ol{counter-reset:section;margin-left:0;padding-left:1.5em}#TableOfContents>ol>li{counter-increment:section}#TableOfContents>ol>li>ol{counter-reset:subsection}#TableOfContents>ol>li>ol>li{counter-increment:subsection}#TableOfContents>ol>li>ol>li::marker{content:counter(section)"." counter(subsection)"  "}#TableOfContents>ol>li::marker{content:counter(section)"  "}#TableOfContents>ol>li::marker,#TableOfContents>ol>li>ol>li::marker{font-family:Source Sans Pro;font-weight:700}footer{margin-top:4em;text-align:center}table{width:100%}img{width:100%;border-radius:3px;margin:1em 0}p>img+em{display:block;transform:translateY(-1em)}sup{line-height:0}p,tbody,li{font-family:Source Sans Pro;color:var(--gray);line-height:1.5em}h2{opacity:.85}h3{opacity:.75}blockquote{margin-left:0;border-left:3px solid var(--secondary);padding-left:1em;transition:border-color .2s ease}blockquote:hover{border-color:var(--tertiary)}table{padding:1.5em}td,th{padding:.1em .5em}.footnotes p{margin:.5em 0}article a{font-family:Source Sans Pro;font-weight:600;text-decoration:underline;text-decoration-color:var(--tertiary);text-decoration-thickness:.15em}sup>a{text-decoration:none;padding:0 .1em 0 .2em}pre{font-family:fira code;padding:.75em;border-radius:3px;overflow-x:scroll}code{font-family:fira code;font-size:.85em;padding:.15em .3em;border-radius:5px;background:var(--lightgray)}html{scroll-behavior:smooth}body{margin:0;height:100vh;width:100vw;overflow-x:hidden;background-color:var(--light)}@keyframes fadeIn{0%{opacity:0}100%{opacity:1}}footer{margin-top:4em}footer>a{font-size:1em;color:var(--secondary);padding:0 .5em 3em}hr{width:25%;margin:4em auto;height:2px;border-radius:1px;border-width:0;color:var(--dark);background-color:var(--dark)}a[href^="/"]{text-decoration:none;background-color:#afbfc922;padding:0 .2em;border-radius:3px}.singlePage{margin:4em 30vw}@media all and (max-width:1200px){.singlePage{margin:25px 5vw}}.page-end{display:flex;flex-direction:row}@media all and (max-width:780px){.page-end{flex-direction:column}}.page-end>*{flex:1 0}.page-end>.backlinks-container>ul{list-style:none;padding-left:0;margin-right:2em}.page-end>.backlinks-container>ul>li{margin:.5em 0;padding:.25em 1em;border:var(--outlinegray)1px solid;border-radius:5px}.page-end #graph-container{border:var(--outlinegray)1px solid;border-radius:5px}.centered{margin-top:30vh}</style><style>.darkmode{text-align:right}.darkmode>.toggle{display:none;box-sizing:border-box}.darkmode>.toggle:checked+.toggle-button:after{left:50%}.darkmode>.toggle+.toggle-button{box-sizing:border-box;outline:0;display:inline-block;width:3em;height:1.5em;position:relative;cursor:pointer;border:2px solid var(--gray);user-select:none;padding:2px;transition:all .2s ease;border-radius:2em}.darkmode>.toggle+.toggle-button:after,.darkmode>.toggle+.toggle-button:before{position:relative;display:block;box-sizing:border-box;content:"";width:50%;height:100%}.darkmode>.toggle+.toggle-button:before{display:none}.darkmode>.toggle+.toggle-button:after{left:0;transition:all .2s ease;background:var(--gray);content:"";border-radius:1em}.darkmode #dayIcon{position:relative;width:20px;height:20px;top:-1.5px;margin:0 7px;fill:var(--gray)}.darkmode #nightIcon{position:relative;width:18px;height:18px;top:-2px;margin:0 7px;fill:var(--gray)}</style><style>.chroma{color:#f8f8f2;background-color:#282a36}.chroma .lntd{vertical-align:top;padding:0;margin:0;border:0}.chroma .lntable{border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block}.chroma .hl{display:block;width:100%;background-color:#ffc}.chroma .lnt{margin-right:.4em;padding:0 .4em;color:#7f7f7f}.chroma .ln{margin-right:.4em;padding:0 .4em;color:#7f7f7f}.chroma .k{color:#ff79c6}.chroma .kc{color:#ff79c6}.chroma .kd{color:#8be9fd;font-style:italic}.chroma .kn{color:#ff79c6}.chroma .kp{color:#ff79c6}.chroma .kr{color:#ff79c6}.chroma .kt{color:#8be9fd}.chroma .na{color:#50fa7b}.chroma .nb{color:#8be9fd;font-style:italic}.chroma .nc{color:#50fa7b}.chroma .nf{color:#50fa7b}.chroma .nl{color:#8be9fd;font-style:italic}.chroma .nt{color:#ff79c6}.chroma .nv{color:#8be9fd;font-style:italic}.chroma .vc{color:#8be9fd;font-style:italic}.chroma .vg{color:#8be9fd;font-style:italic}.chroma .vi{color:#8be9fd;font-style:italic}.chroma .s{color:#f1fa8c}.chroma .sa{color:#f1fa8c}.chroma .sb{color:#f1fa8c}.chroma .sc{color:#f1fa8c}.chroma .dl{color:#f1fa8c}.chroma .sd{color:#f1fa8c}.chroma .s2{color:#f1fa8c}.chroma .se{color:#f1fa8c}.chroma .sh{color:#f1fa8c}.chroma .si{color:#f1fa8c}.chroma .sx{color:#f1fa8c}.chroma .sr{color:#f1fa8c}.chroma .s1{color:#f1fa8c}.chroma .ss{color:#f1fa8c}.chroma .m{color:#bd93f9}.chroma .mb{color:#bd93f9}.chroma .mf{color:#bd93f9}.chroma .mh{color:#bd93f9}.chroma .mi{color:#bd93f9}.chroma .il{color:#bd93f9}.chroma .mo{color:#bd93f9}.chroma .o{color:#ff79c6}.chroma .ow{color:#ff79c6}.chroma .c{color:#6272a4}.chroma .ch{color:#6272a4}.chroma .cm{color:#6272a4}.chroma .c1{color:#6272a4}.chroma .cs{color:#6272a4}.chroma .cp{color:#ff79c6}.chroma .cpf{color:#ff79c6}.chroma .gd{color:#8b080b}.chroma .ge{text-decoration:underline}.chroma .gh{font-weight:700}.chroma .gi{font-weight:700}.chroma .go{color:#44475a}.chroma .gu{font-weight:700}.chroma .gl{text-decoration:underline}.lntd:first-of-type>.chroma{padding-right:0}.chroma code{font-family:fira code!important;font-size:.85em;line-height:1em;background:0 0;padding:0}.chroma{border-radius:3px;margin:0}</style></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-XYFD95KB4J"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-XYFD95KB4J',{anonymize_ip:!1})}</script><body><div class=singlePage><div class=darkmode><label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label class=toggle-button for=darkmode-toggle></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div><article><aside class=mainTOC><h3>Table of Contents</h3><nav id=TableOfContents><ol><li><ol><li><a href=#introduction>Introduction</a></li><li><a href=#history-of-ideas>History of Ideas</a></li></ol></li><li><a href=#chapter-1>Chapter 1</a><ol><li><a href=#foundations>Foundations</a></li><li><a href=#neural-dynamics>Neural Dynamics</a></li></ol></li><li><a href=#chapter-2>Chapter 2</a><ol><li><a href=#spaces>Spaces</a></li><li><a href=#activation-fields>Activation Fields</a></li><li><a href=#field-dynamics>Field Dynamics</a></li><li><a href=#attractors-and-instabilities>Attractors and Instabilities</a></li></ol></li><li><a href=#chapter-3-embedding-dft-in-neurophysiology>Chapter 3: Embedding DFT in Neurophysiology</a><ol><li></li><li><a href=#continuous-activation-distributions-from-neural-responses>Continuous Activation Distributions from Neural Responses</a></li></ol></li><li><a href=#chapter-4-embodied-neural-dynamics>Chapter 4: Embodied Neural Dynamics</a><ol><li><a href=#behavioral-dynamics-in-a-braitenberg-vehicle>Behavioral DYnamics in a [[Braitenberg Vehicle]]</a></li><li><a href=#linking-dfs-to-behavioral-dynamics>Linking DFs to Behavioral Dynamics</a></li><li><a href=#embodied-a-not-b>Embodied A Not B</a></li></ol></li></ol><ol><li><a href=#chapter-5-integration-and-selection-in-multidimensional-dynamic-fields>Chapter 5: Integration and Selection in Multidimensional Dynamic Fields</a><ol><li><a href=#neurophysiology-of-higher-dimensional-representations>Neurophysiology of Higher Dimensional Representations</a></li><li><a href=#dynamics-of-higher-dimensional-fields>Dynamics of Higher Dimensional Fields</a></li><li><a href=#real-time-integration-and-selection-in-dfs>Real-time Integration and Selection in DFs</a></li><li><a href=#integration--selection-in-autonomous-visual-exploratory-systems>Integration & Selection in Autonomous Visual Exploratory Systems</a></li><li><a href=#vwm--and-saccade-orienting-in-remote-distractor>VWM and Saccade Orienting in Remote Distractor</a></li><li><a href=#function-and-fallibility-of-visual-feature-integration>Function and Fallibility of Visual Feature Integration</a></li></ol></li><li><a href=#chapter-6-integrating-perception-and-working-memory-in-a-three-layer-dynamic-field-model>Chapter 6: Integrating Perception and Working Memory in a Three-Layer Dynamic Field Model</a><ol><li><a href=#integrating-perceptual-and-memory-processes-in-3-layer-nf-architecture>integrating perceptual and memory processes in 3-layer NF architecture</a></li><li><a href=#spatial-recall-biases>Spatial recall biases</a></li><li><a href=#visual-change-detection>Visual Change Detection</a></li><li><a href=#behavioral-signatures-of-the-3-layers>Behavioral Signatures of the 3 Layers</a></li><li><a href=#comparison-with-other-models>Comparison with Other Models</a></li></ol></li><li><a href=#chapter-7-sensory-motor-and-cognitive-transformation>Chapter 7: Sensory-Motor and Cognitive Transformation</a><ol><li><a href=#role-of-reference-frames>Role of Reference Frames</a></li><li><a href=#reference-frame-transformations---gain-modulation>Reference Frame Transformations - Gain Modulation</a></li><li><a href=#reference-frame-transformations---df-model>Reference Frame Transformations - DF Model</a></li><li><a href=#extensions-of-the-basic-mechanism>Extensions of the Basic Mechanism</a></li><li><a href=#multidirectional-transformations>Multidirectional Transformations</a></li></ol></li><li><a href=#chapter-8-integrating-what-and-where>Chapter 8: Integrating What and Where</a></li></ol></nav></aside><p>[[Books]] [[Neuroscience]]</p><h1 id=dynamic-thinking-a-primer-on-dynamic-field-theory>Dynamic Thinking: A Primer on Dynamic Field Theory</h1><h1 id=foundations-of-dynamic-field-theory>Foundations of Dynamic Field Theory</h1><h3 id=introduction>Introduction</h3><ul><li>Provides neural process accounts for a large swath of behaviors and cognitive abilities</li></ul><h3 id=history-of-ideas>History of Ideas</h3><ul><li>Roots in motor/muscle control theory</li><li>Stability is N&S for coordination patterns</li><li>Can cognition arise directly from action-perception in closed loop</li><li>Representational states</li><li>Biological models do give rise to DFT dynamics</li><li>DFT valid all the way from motor behavior to higher cognition</li><li>Integration: follow common principles</li></ul><hr><h2 id=chapter-1>Chapter 1</h2><h3 id=foundations>Foundations</h3><ul><li>[[Braitenberg Vehicle]] - neural account of behavior<ul><li>Sensors, effectors, nervous systems, bodies</li><li>![[Pasted image 20210513090719.png]]</li><li>Taxis vehicle - orients towards stimulus</li><li>![[Pasted image 20210513090909.png]]</li><li>Structured environment - meaningful behavior</li><li>fifth component of the vehicle</li><li>vehicle + environment - dynamical system</li></ul></li><li>C1 - closed loops to create internal attractor states that are active even after input is removed</li><li>C2 - origin of neural activation variables</li><li>C3 - neural foundations of dynamic fields - real neurons</li><li>C4 - behavioral dynamics + DFT = cognition</li></ul><h3 id=neural-dynamics>Neural Dynamics</h3><ul><li>Neural processes from which behavior emerges evolve continuously in time; linked to each other and sensory info</li><li>stability essential</li><li>dynamic instability</li></ul><h4 id=activation>Activation</h4><ul><li>activity of pops - related to behavioral patterns</li><li>[[Mean Field Approximation]] - population activation vs. its rate of change - sigmoidal relation</li><li>Discrete spiking events not accounted for in mean-field</li><li>Continuous time approximation - spikes frequent enough</li><li>Relation:<ul><li>state of world influences activation level</li><li>activation level influences world through motor actions</li></ul></li></ul><h4 id=neural-dynamics-1>Neural Dynamics</h4><ul><li>$\tau\dot{u}=f(u)$<ul><li>$u$ - activation variable</li><li>stability requirement</li></ul></li><li>Noise: $\tau\dot{u}=f(u)+q\zeta(t)$<ul><li>$\zeta(t)$: AWGN</li></ul></li></ul><blockquote><p>Euler&rsquo;s Numerical Method
$u(t_i)=u(t_{i-1})+\Delta tf(u(t_{i-1}))$
With noise:
$u(t_i)=u(t_{i-1})+\Delta tf(u(t_{i-1})) + \sqrt{\Delta t}q\zeta(t_{i-1})$</p></blockquote><ul><li>Noise addition to constant activation<ul><li>$\tau\dot{u}=\zeta(t)$</li><li>![[Pasted image 20210513105024.png]]</li><li>Random walk; Brownian motion</li></ul></li><li>With stabilizing force:<ul><li>$\tau\dot{u}=-u+h+\zeta(t)$</li><li>![[Pasted image 20210513105225.png]]</li></ul></li><li>Convergence to fixed point - relaxation</li></ul><h4 id=self-excitation-and-detection-instability>Self-Excitation and Detection Instability</h4><ul><li>Interaction - recurrence</li><li>$\tau\dot{u}=-u+h+s(t)+cg(u)$<ul><li>$s(t)$ - input</li><li>$g(u)$ - sigmoid threshold</li><li>![[Pasted image 20210513110839.png]]</li><li>![[Pasted image 20210513110910.png]]</li><li>Bifurcation - collision/splitting of fixed points</li></ul></li><li>Detection instability<ul><li>decision that significant input has been detected</li><li>stabilized - held even if input drops</li><li>necessary in real systems</li></ul></li><li>If input drops low enough - back to monostable off regime<ul><li>reverse detection instability</li></ul></li><li>Decision hysteresis<ul><li>![[Pasted image 20210513111626.png]]</li><li>inertia of response</li><li>detection of apparent motion - visual motion seen between location where there is luminance change<ul><li>BRLC - background relative luminance contrast</li><li>motion detected at higher values</li></ul></li></ul></li><li>Attractors are not stationary<ul><li>Arise depending on input</li></ul></li></ul><h4 id=sustained-activation-and-working-memory>Sustained Activation and Working Memory</h4><ul><li>Stimulation does not uniquely determine inner state - hysteresis</li><li>Working memory - bistable coexistence of off and on states</li><li>Input triggers activation into on state, where it can remain indefinitely</li><li>![[Pasted image 20210513112523.png]]</li></ul><h4 id=inhibitory-interaction-and-selection>Inhibitory Interaction and Selection</h4><ul><li>Two activation variables</li><li>$\tau\dot{u_1}=-u_1+h+s_1(t)-c_{12}g(u_2)+\zeta_1(t)$</li><li>$\tau\dot{u_2}=-u_2+h+s_2(t)-c_{21}g(u_1)+\zeta_2(t)$</li><li>Same resting level but different input, different noise sources</li><li>![[Pasted image 20210513112851.png]]</li><li>Mutual inhibitory coupling</li><li>Assume $u_2>0$ before $u_1$ left its resting level</li><li>u1 gets pulled down</li><li>u2 wins competition</li><li>![[Pasted image 20210513113215.png]]<ul><li>Top: the gray line is the dynamics of u1 when u2 is sufficiently below zero so that the sigmoid yields zero.</li><li>Bottom: The solid black line is the dynamics of u2 when u1 is below zero.</li></ul></li><li>Activating one suppresses the other</li><li>Attractor of second pushed way below zero</li><li>Maintaining the selection decision</li><li>Caveat: if input to suppressed variable is very high, it oculd overcome</li><li>![[Pasted image 20210513113522.png]]<ul><li>Left: The dynamics of one of two competing activation variables is plotted in three cases: without external input (solid), and with external input but without (dotted) versus with (dashed) inhibition from the other activation variable.</li><li>Right: Activation trajectories for both activation variables are shown (one in solid black, the other in solid gray).</li><li>Same input but random fluctuations tip the balance</li></ul></li></ul><hr><h2 id=chapter-2>Chapter 2</h2><ul><li>What exactly do activation variables &lsquo;stand for&rsquo;?</li><li>Is truly categorical perception ever valid?</li><li>Continuous states of the world are primary</li></ul><h3 id=spaces>Spaces</h3><ul><li>Continuous variation of objects in vision</li><li>Dimensions to describe real-world percepts</li><li>![[Pasted image 20210514180024.png]]</li></ul><h3 id=activation-fields>Activation Fields</h3><ul><li>Continuum of activation variables, labeled by continuous position</li><li>Width, peak of activation field denotes preferred stimulus</li><li>Peak of activation signify:<ul><li>Fact that instance has been created that can affect other downstream networks (go signals)</li><li>Location of peak - metric information along the dimensions - estimate of perceptual state</li></ul></li><li>One stimulus followed by two:</li><li>![[Pasted image 20210514181439.png]]</li><li>Depending on angular separation, network perceives three different things:<ul><li>Averaging (fusion)</li><li>Splitting (transparency)</li><li>Selection</li></ul></li></ul><h3 id=field-dynamics>Field Dynamics</h3><ul><li><p>Activation field: $u(x,t)$</p></li><li><p>Governing equation similar to single activation variable:</p><ul><li>$\tau\dot{u}(x,t)=-u(x,t)+h+s(x,t)+ \int k(x-x')g(u(x',t))dx'$</li><li>Integral is continuous version of sum over all field sites</li><li>Each location $x'$ &rsquo;s contribution weighted by $g$</li><li>Strength of supra-threshold contributions - function $k(x-x')$ of distance between the sites</li><li>$k(x-x')>0$ for close distances, $k(x-x')&lt;0$ for larger distances</li><li>Homogeneous - shifted versions of solutions also solutions</li><li>Localized inputs $s(x,t)$ break homogeneity</li><li>$k$ - analogous to synaptic weights</li></ul></li><li><p>Boundary condition on convolution: Value at borders are same (periodic)</p><ul><li>Natural for circular fields like heading</li><li>Also works for things like visual field since activation diminishes at the edges</li></ul></li><li><p>Activation peaks - attractors</p><ul><li>Local excitatory interaction stabilizes peaks</li><li>Inhibitory interaction over longer distances counter balances</li><li>![[Pasted image 20210514183202.png]]</li></ul></li><li><p>Relation between activation fields and discrete activation variables</p></li><li><p>![[Pasted image 20210514183449.png]]</p><ul><li>Global inhibition :: Mutual inhibition</li><li>Local Excitation :: Self excitation</li></ul></li><li><p>Local populations are the substrate for representation (not individual neurons)</p></li></ul><h3 id=attractors-and-instabilities>Attractors and Instabilities</h3><ul><li>Sub-threshold and self-stabilized activation patterns</li><li>Meaning of instabilities</li></ul><h4 id=detection>Detection</h4><ul><li>Simplest stable state - activation&lt;0, only weak inputs<ul><li>Interaction disengaged; field dynamics at each point independent</li><li>Stationary solution: sub-threshold attractor state<ul><li>$u_0(x,t)=h+s(x,t)$</li><li>Disappears in presence of sufficiently strong input</li><li>![[Pasted image 20210514190201.png]]</li></ul></li></ul></li><li>Interaction engaged when activation approaches zero from below anywhere</li><li>Gaussian input:</li><li>![[Pasted image 20210514191858.png]]</li><li>New attractor - hill</li><li>Reinforced by positive feedback</li><li>Range of inputs exists where sub-threshold hill and peak are both stable : bistable state<ul><li>But only one can be realized at a time</li><li>Which one depends on history of activation</li></ul></li><li>When input falls below a critical level, mechanism that keeps peak stable begins to fail<ul><li>Reverse detection instability</li></ul></li><li>&lsquo;Detection Instability&rsquo; described above - stable detection decisions even with fluctuating sensory input</li><li>Emergence of discrete-time events (detection decision) from continuous time input<ul><li>Peak remains coupled to continuously varying input afterwards, however</li></ul></li><li>Position of peak - estimate of location of maximum of input<ul><li>peak tracks as input moves - lags behind though</li><li>may lose tracking if input fast enough - decay and formation of new peak when it detects again</li></ul></li></ul><h4 id=working-memory>Working Memory</h4><ul><li>Reverse detection instability doesn&rsquo;t always occur<ul><li>Large (less negative) resting level => lot of self-excitation</li><li>Sustained peak in absence of input</li></ul></li><li>Significance: memory of past locations of inputs<ul><li>Accepted theory of working memory</li></ul></li><li>Sustained peaks &lt;=> self-stabilized peaks</li><li>![[Pasted image 20210515100819.png]]<ul><li>Left - monostable state in absence of input</li><li>Right - bistable in absence of input (larger h)</li><li>Self-stabilized peak actually continuum of attractors as location can be shifted along dimension</li></ul></li></ul><h4 id=selection>Selection</h4><ul><li>In presence of multiple peaks in input, first peak to arise (depends on input and weight) stabilizes and suppresses others</li><li>Input patterns that match pattern of synaptic connectivity provide strongest excitation<ul><li>Lumped into $s(x,t)$</li></ul></li><li>First peak suppresses others even if input to those locations is stronger/equal later</li><li>![[Pasted image 20210515101800.png]]<ul><li>Form of robust estimation</li></ul></li><li>Limitations:<ul><li>When input is sufficiently different, decision may be reversed</li><li>Selection instability</li></ul></li><li>Limit on number of simultaneous peaks - Inhibitory strength<ul><li>Each peak inhibits rest of the region</li><li>Hence total number possible is limited</li></ul></li><li>Unlimited instabilities<ul><li>Transition from multiple-peaks-stable to single-peak-stable</li><li>Transitions from n-stable to m-stable</li></ul></li><li>Two peaks in bistable move close to each other - transition to monostable</li><li>Preshaping by inhomogeneous input + homogeneous brief boost => self-sustained peak<ul><li>Can impact downstream dynamics by amplifying noise</li><li>Can alleviate demands on sensory input - they need to only deliver small amounts of input<ul><li>Bootstrapping fields from sensory-motor domain</li></ul></li></ul></li><li>![[Pasted image 20210515103035.png]]</li></ul><h4 id=memory-trace>Memory Trace</h4><ul><li>Sustained peaks susceptible to capacity limits and interference</li><li>Interference when new sensory information competes with existing peaks</li><li>Learning - longer time scale than peak formation etc.</li><li>Instance of self-excited peak formation - leaves memory trace that enables re-emergence of same peak</li><li>![[Pasted image 20210515103724.png]]</li><li>Memory trace - second layer of dynamics on a slower time scale<ul><li>Remembers past locations of peaks</li><li>Decays at locations where there are no peaks</li><li>Stays constant in absence of new peaks</li><li>Provides weak excitatory input back to activation fields thereby facilitating remembrance</li></ul></li><li>$\tau_{mem}\dot{u}_{mem}(x,t)=-u_{mem}(x,t)=g(u(x,t))$</li><li>$\tau_{mem}&#187;\tau$</li><li>Coupling of memory trace and field dynamics:</li><li>$\tau\dot{u}(x,t)=-u(x,t)+h+s(x,t)+ c_{mem}u_{mem}(x,t)+ \int k(x-x')g(u(x',t))dx'$<ul><li>Strength : $c_{mem}$</li></ul></li><li>Memory trace does not evolve when no location has peaks</li><li>Memory trace represents probability of events</li><li>Example: 2-choice task where frequency of each task varies according to conditions<ul><li>Response times vary with probability of each choice</li><li>Shorter for more frequent task</li><li>Memory trace converges to levels that reflect frequency of each choice - lead to pre-activation of field</li><li>Exact law - Response time ~ log(choice probability)<ul><li>Arises from exponential time course of activation as it relaxes to the attractor</li></ul></li><li>Prior probability representation based on history</li><li>![[Pasted image 20210515104914.png]]</li><li>Trace becomes mechanism for category formation</li><li>Peak not at input location but actually at pre-shaped location</li><li>Will not vary with small changes in input location</li><li>Effectively a classifier now, parametrized by memory trace</li><li>Unsupervised learning</li></ul></li></ul><h4 id=illustration-dft-model-of-perseverative-reaching>Illustration: DFT Model of Perseverative Reaching</h4><ul><li><p>A-not-B task</p></li><li><p>Trial on infants:</p><ul><li>Two wells A and B</li><li>Toy placed into A (in sight of infant) first few times, infants allowed to search, look in A first</li><li>Next time hidden in B, allowed to search, some look in A still</li><li>Stop making mistake around 1 year of age</li></ul></li><li><p>![[Pasted image 20210515105858.png]]</p><ul><li>Green - motor choice</li><li>Pink - Placing of object</li><li>Violet - Two discrete location</li><li>Grey - previous repetitions of task</li><li>Blue - Forcing choice by need for toy</li></ul></li><li><p>Large memory trace explains why mistake is made</p></li><li><p>A trial:</p></li><li><p>![[Pasted image 20210515110235.png]]</p></li><li><p>B trial:</p></li><li><p>![[Pasted image 20210515110314.png]]</p><ul><li>Memory trace input lasts longer than stimulus input</li><li>B-peak decays at end of delay => A peak forms again</li><li>A-not-B error</li></ul></li><li><p>Older infants - higher resting levels of motor planning field (h)</p><ul><li>Stronger interaction</li><li>Push through memory instability</li><li>Sustained peaks in absence of input possible</li></ul></li><li><p>![[Pasted image 20210515110707.png]]</p><ul><li>B peak sustained - working memory regime</li></ul></li><li><p>Consequence:</p><ul><li>Spontaneous errors in original A runs affect A-not-B error</li></ul></li><li><p>Sandbox task</p><ul><li>On infants who would never make A-not-B mistake on original task</li><li>Toy buried in A/B locations in sandbox, allowed to dig</li><li>After many A-runs, dig in location near A even on B-run</li><li>Effect seen on children as old as 6 years</li></ul></li><li><p>No discrete locations like in previous task => no task input</p></li><li><p>First B trial:</p><ul><li>A and B location sufficiently close; peak at B affected by memory trace at A:</li><li>![[Pasted image 20210515111505.png]]</li><li>Cause of error here different from original task</li><li>Drift rather than forgetting as there is no input to keep peak centered at B</li><li>Memory trace wider due to drifting peak</li><li>A and B far apart; no metric bias:</li><li>![[Pasted image 20210515111951.png]]</li></ul></li></ul><hr><h2 id=chapter-3-embedding-dft-in-neurophysiology>Chapter 3: Embedding DFT in Neurophysiology</h2><ul><li>DFT not merely an analogy</li><li>Distribution of Population Activation (DPA)<ul><li>Firing rate of group -> continuous distribution of activation over feature space</li><li>Link between DFT and biology</li></ul></li><li>Extension of basic DF model: two-layer field</li></ul><h4 id=neural-activation---perception-cognition-behavior>Neural Activation -> Perception, Cognition, Behavior</h4><ul><li>Tuning curve: spike rate vs. stimulus/parameter dimension</li><li>Gaussian-like tuning curves very common</li><li>![[Pasted image 20210517153345.png]]</li><li>Receptive field: range where the tuning curve differs from baseline<ul><li>for spatially tuned sensory neurons</li></ul></li><li>Receptive field profile: structure of tuning curve in receptive field</li><li>Neurons typically tuned along >1 dimension</li><li>Tuning curves of neuron set scattered over input dimension</li><li>How to decode activity:<ul><li>WTA scheme: not robust against noise<ul><li>not stable</li><li>ambiguous (1 spike rate :: 2 values (Gaussian))</li></ul></li><li>Information is carried collectively</li></ul></li><li>Population coding: properties of events reflected by distribution of activation over population</li><li>![[Pasted image 20210517154021.png]]</li><li>Distribution over A,B,C unique for each input value</li><li>Naturally robust to noise due to numbers</li><li>Experimental verification of population coding: Does it predict behavior more reliably than single neurons? Do all active neurons impact behavior? :: Yes</li></ul><h5 id=superior-colliculus---saccade-control>Superior colliculus - Saccade Control</h5><ul><li>Tuning along angular direction and amplitude</li><li>Would expect clustering in one region - observed too</li><li>A,B,C - Centers of blob that would give rise to saccade vectors A,B,C</li><li>Do neurons on periphery of blob also matter?<ul><li>Tested by anesthetizing periphery neurons then providing stimulus</li></ul></li><li>![[Pasted image 20210517154549.png]]<ul><li>b) A region anesthetized - output (ideally A) unaffected (!!)</li><li>c) A region anesthetized - output (ideally B) shifts towards D</li></ul></li><li>Hence, overall activation profile more important than strongest ones</li></ul><h5 id=arm-movement>Arm Movement</h5><ul><li>Experiment: Need to move arm from center to 1 of 8 buttons equidistant from center</li><li>Population vector constructed for each movement direction<ul><li>Find preferred direction for each neuron</li><li>Measure response for required direction</li><li>Wight preferred direction vector by activity and sum</li><li>$w_i(M)=d_i(M)-b_i$</li><li>$d_i(M)$: spike rate of neuron $i$ for direction M</li><li>$b_i$: bias/baseline spike rate</li><li>$P(M)=\sum_iw_i(M)C_i$</li><li>$C_i$: Preferred direction vector of neuron $i$</li></ul></li><li>More active neurons contribute more etc.</li><li>Pop. vector compared to actual arm movement</li><li>If all neurons relevant => more neurons included, more accurate : observed</li><li>![[Pasted image 20210517155952.png]]<ul><li>a) Ideal tuning curves</li><li>b) Vectors of 8 possible movements</li><li>c) Vectors weighted by spike rate during movement<ul><li>length: contribution</li></ul></li></ul></li></ul><blockquote><p>Possibilities: Motor acts competition, multiple items in working memory etc.</p></blockquote><h3 id=continuous-activation-distributions-from-neural-responses>Continuous Activation Distributions from Neural Responses</h3><ul><li>Bridge gap between biological neural populations and DFs</li><li>Transition from set of discrete values to continuous distributions</li><li>May seem straightforward but mathh rigorr grr</li><li>Refer [[#Arm Movement]]<ul><li>Each neuron stands for its preferred direction vector</li><li>Estimate is an activity weighted sum</li></ul></li><li>Lot of information lost when distribution reduced to one vector<ul><li>Width and shape of distribution :: matter<ul><li>Few neurons strongly overlapping (or) Many neurons moderately activated</li></ul></li><li>Multimodal distributions of activity<ul><li>Average could be an unimportant value</li></ul></li></ul></li><li>Time to construct DPA from tuning curves</li><li>DPA provides direct link to DF models</li></ul><h4 id=construction-of-dpas-from-gaussian-tuning-curves>Construction of DPAs from Gaussian Tuning Curves</h4><ul><li>Estimate tuning curves of neurons</li><li>Receptive field center estimated manually<ul><li>Used as basis for more precise assessment</li><li>Smoothed with Gaussian filter</li><li>Center of mass of output used as center for Gaussian tuning curve of fixed width</li><li>![[Pasted image 20210517183818.png]]</li><li>Exact shape of receptive field lost in this process</li></ul></li><li>DPA now constructed using this set of Gaussian tuning curves<ul><li>Normalize firing rate</li><li>Tuning curve weighted by normalized firing rate and summed</li><li>![[Pasted image 20210517184137.png]]</li><li>Green - normalized TCs of neurons</li><li>Black - firing rate from one experimental condition</li><li>Blue - weighted TCs</li><li>Red - Sum</li></ul></li></ul><blockquote><p>Equations:
$f_i(x,y)=N([m_{x_i},m_{y_i}],\sigma^2)$
$\tilde{r}_i(a,t)=\frac{r_i(a,t)-b_i}{r_{m_i}-b_i}$
$u(x,y)=\frac{\sum_ir_i(a,t)f_i(x,y)}{\sum_if_i(x,y)}$</p></blockquote><ul><li>Activation value for each position even if no neuron&rsquo;s center at that location</li><li>![[Pasted image 20210517185143.png]]<ul><li>a) Stimuli location b) Receptive fields c) Constructed DPA d) DPA from one stimulus</li></ul></li><li>![[Pasted image 20210517185931.png]]<ul><li>DPA from stimuli at different positions</li><li>Activation peaks in DPA widened over time contrary to belief that response gets sharpened over time</li></ul></li><li>Final normalization step<ul><li>Divide weighted sum of tuning curves by unweighted sum of tuning curves</li><li>Some regions may be sampled more densely by neurons eg. center portion in TC figure above</li><li>Will result in high activation value purely due to numbers</li><li>Compensate for this</li></ul></li><li>Still need good sample size of neurons in field</li><li>Goodness of DPA can be determined by comparing with actual DPA produced by stimuli</li></ul><h4 id=constructing-dpas-for-movement-preparation>Constructing DPAs for Movement Preparation</h4><ul><li>Move arm from center to 1 of 6 targets<ul><li>Direction indicated by red LEDs</li><li>Priming by green LEDs on possible upcoming locations</li><li>Varying levels of certainty</li><li>![[Pasted image 20210517191630.png]]</li><li>PS: Preparatory signal, RS: Response signal, MVT: Movement onset, PP: Preparatory period, RT: Reaction time</li></ul></li><li>Feature space: Direction of arm movement</li><li>Tuning curves determined directly from neural responses</li><li>Average firing rate obtained by averaging over all trials, with different PSs and over RT period</li><li>Individual properties of tuning curve preserved (width etc.)</li><li>Same procedure as above to construct DPA, with the final normalization step being a subtractive one instead of divisive</li></ul><blockquote><p>Raw tuning curves:
$\tilde{f}<em>i(x_k)=\langle r_i(x_k,t</em>{rtp})\rangle$
Average is over trials. Real tuning curves obtained by normalizing to interval [0,1]
DPA:
$u(x)=\sum_ir_i(a,t)f_i(x)-\sum_ir_i(a,t_{pre})f_i(x)$
$a$: trial condition, $t$: time interval, $t_{pre}$: window before stimulus presentation
Subtractive term is the normalization</p></blockquote><ul><li>DPA only provides values for the 6 directions, not a continuous field</li><li>Less smooth than Gaussian method from earlier, but actually more accurate</li><li>Constructed DPAs show single peak for target locations => great</li><li>![[Pasted image 20210517193041.png]]<ul><li>Priming signal certainty affects initial peak</li><li>More uncertainty => weaker activation</li><li>Peak formation after target signal</li></ul></li><li>Thus, population doesn&rsquo;t encode single value; contains additional aspects such as certainty of upcoming movement</li><li>Shape of distribution &lt;-> certainty of movement</li><li>DPA can be used to describe time course of activity also, as can be seen above</li><li>New trials: RTs higher/lower than median<ul><li>Total activity larger in fast RT trials</li><li>Activity concentration higher in fast RT trials</li><li>DPAs &lt;-> Reaction time (behavioral variable)</li></ul></li><li>DPA useful even if neurons don&rsquo;t form topographical map<ul><li>Motor cortex doesn&rsquo;t have spatial field like vision but DPA works over behavioral variable field, hence results independent of physical arrangement of neurons</li></ul></li></ul><h4 id=lateral-interactions-in-primary-visual-cortex>Lateral Interactions in Primary Visual Cortex</h4><ul><li>Sustained activation &lt;-> interaction within population</li><li>Response to elementary vs. complex stimuli</li><li>![[Pasted image 20210522123235.png]]<ul><li>b) Constructed DPA for complex stimuli (solid) vs. superposition of DPAs for elementary stimuli (dashed)<ul><li>Repulsion of peaks in distant case</li></ul></li><li>c) Calculated time course of activation</li><li>d) Time course of activation from DF model</li></ul></li><li>Deviation from superposition => existence of interactions<ul><li>Composite almost always weaker than superposition of elementary</li><li>During early part of stimulation for nearby case, activation higher in composite case though; also died down faster</li></ul></li><li>![[Pasted image 20210522123819.png]]</li></ul><h4 id=modeling-interaction-effects-with-dfs>Modeling Interaction Effects with DFs</h4><ul><li>Lateral interaction -> strengthen similar neurons</li><li>Same as peak formation and sustenance mechanism in DFT</li><li>New Model:<ul><li>Separation of field into exc. and inh. layers</li><li>Can account for repulsion effect<ul><li>More inhibition on one side than another in bimodal case => drift apart</li></ul></li></ul></li></ul><h4 id=two-layer-dfs>Two-Layer DFs</h4><ul><li>Dale&rsquo;s law: Neurons emit same set of neurotransmitters at all their synapses<ul><li>Very few exceptions</li></ul></li><li>Implications:<ul><li>A neuron can only have one effect on another single neuron at all times</li><li>Inhibition has a delay => initial overshoot of excitation</li></ul></li><li>Two-layer field structure:<ul><li>![[Pasted image 20210522130447.png]]</li><li>Only excitatory receives external input</li><li>topological projections</li><li>no lateral interaction within inhibitory layer</li><li>Inhibition AoE wider if kernel sizes for exc-exc exc-inh and inh-exc are same (2x spreading)</li><li>To simplify: exc-inh kernel point-like (no spreading) and inh-exc kernel 2x wider</li></ul></li><li>For some configurations, 2-layer DF can act as oscillator<ul><li>Can be nullified by using different time constants</li></ul></li><li>Selection decisions also possible</li><li>Equations:<ul><li>Activation of exc. layer: $u$</li><li>Activation of inh. layer: $v$</li><li>Kernels: $k_{uu},k_{uv},k_{vu}$<ul><li>First letter target, second origin</li></ul></li><li>$\tau_u\dot{u}(x,t)=-u(x,t)+h_u+s(x,t)+ \int k_{uu}(x-x')g(u(x',t))dx'-\int k_{uv}(x-x')g(v(x',t))dx'$</li><li>$\tau_v\dot{v}(x,t)=-v(x,t)+h_v+s(x,t)+ \int k_{vu}(x-x')g(u(x',t))dx'$</li><li>$k_{uu}(x-x')=c_{uu}N(x',\sigma_{uu}^2)$</li><li>For point-to-point connection from $u$ to $v$:<ul><li>$k_{vu}(x-x')=\delta(x-x')$</li></ul></li></ul></li></ul><h4 id=fitting-neural-data-for-movement-preparation-with-dfs>Fitting Neural Data for Movement Preparation with DFs</h4><ul><li>Single inhibitory node</li><li>cf. [[#Constructing DPAs for Movement Preparation]]</li><li>Activation profile broader for more pre-cued locations but also flatter due to inhibitory normalization</li></ul><h4 id=relationship-between-dpas-dfs-and-neural-populations>Relationship between DPAs, DFs and Neural Populations</h4><ul><li>DPA: firing rates &lt;-> continuous activation distribution<ul><li>Does not explain emergence/evolution of activation patterns</li><li>Can only be determined for parameter spaced for which tuning curves are measured</li><li>Choosing inappropriate feature space can lead to misleading results</li></ul></li><li>DF: Generative models, linked with biological data<ul><li>Makes predictions about activation patterns</li><li>Do not attempt to fully explain activation pattern of a single population, only that which is relevant to a single task</li></ul></li></ul><p>Can stability be retained as a property of neural processing while still representing high-dimensional information?
[[Hopfield Network]]</p><hr><h2 id=chapter-4-embodied-neural-dynamics>Chapter 4: Embodied Neural Dynamics</h2><ul><li>How does closing sensory motor loop affect neural dynamics<ul><li>Creates behavioral dynamics</li><li>Not the same as activation variables</li><li>emergence of decisionsn from environment conditions</li></ul></li></ul><h3 id=behavioral-dynamics-in-a-braitenberg-vehicle>Behavioral DYnamics in a [[Braitenberg Vehicle]]</h3><ul><li>Sensors, effectors, body linking the two mechanically, nervous system linking to two though activation variables</li><li>Situated in structured environment</li><li>Taxis vehicle<ul><li>![[Pasted image 20210602084435.png]]</li><li>Activation plays limited role, only a transducer</li><li>Moves towards stimulus by using difference in intensity as control variables</li></ul></li><li>Goal: formalize dynamics of this vehicle<ul><li>Function emerges from behavioral dynamics</li><li>Stability determines the functions that emerge</li></ul></li><li>![[Pasted image 20210602091914.png]]</li><li>Compose the functions relating intensity difference, activation, turning rate to directly obtain difference in turning rates as function of heading direction</li><li>Turning rate is time derivative of heading<ul><li>$\dot{\phi}=f(\phi)$</li><li>Behavioral dynamics<ul><li>Abstract concept - removes details of mechanisms of sensory and effector systems</li></ul></li></ul></li><li>Attractor state:<ul><li>![[Pasted image 20210602092500.png]]</li><li>Only relative orientation matters, absolute coordinate system doesn&rsquo;t</li></ul></li><li>Does not account for average turning rate which causes forward motion<ul><li>Changing intensity profile leads to changing behavioral dynamics</li></ul></li><li>Bimodal system:<ul><li>![[Pasted image 20210602094213.png]]</li><li>Bistability leads to a selection decision</li><li>Self-stabilization of decision</li><li>Sensory input no longer uniquely determines behavior, depends on internal state also</li><li>Similar to bistability in neural dynamics</li></ul></li><li>Sources close together:<ul><li>![[Pasted image 20210602094545.png]]</li></ul></li><li>Bifurcation diagram: Pitchfork<ul><li>![[Pasted image 20210602094715.png]]</li></ul></li><li>DIfference between behavioral dynamics and cybernetics<ul><li>In cybernetics, the input signal is an error/deviation from a goal or &lsquo;set point&rsquo;</li><li>Similar to classical control theory, but unclear how to analyze in case of multiple sources</li><li>Formalizing as behavioral dynamics makes explicit the role of environment</li></ul></li></ul><h3 id=linking-dfs-to-behavioral-dynamics>Linking DFs to Behavioral Dynamics</h3><ul><li>Additional decisions to withstand distraction -> inner state cairables</li><li>Phonotaxis vehicle:<ul><li>![[Pasted image 20210607114519.png]]</li><li>5 mics 45 dgrees apart</li><li>60 degree sensitivty cone per mic</li><li>![[Pasted image 20210607114634.png]]<ul><li>Top - Weighted sum of tuning curves</li><li>Middle - Weighted tuning curves</li><li>Bottom - Sensitivity cones</li></ul></li></ul></li><li>Limitations of using just mic inputs<ul><li>Intensity variation of source (eg. music)</li><li>Other ambient sources -> apparent direction changes</li></ul></li><li>Use activation fields instead, with mic inputs as sensory inputs<ul><li>Inputs are fixed to vehicle axis, not world axis</li><li>Need to account for this continuous change of coordinates</li><li>$\psi_i=\zeta_i+\phi$</li><li>$\psi_i$ - World coordinates</li><li>$\zeta_i$ - Vehicle coordinates</li><li>Solve by integrating behavioral dynamics equation</li><li>No error correction in world frame -> doesn&rsquo;t matter as it is canceled by the motor command projection</li></ul></li><li>Neural dynamics driven directly by sensors:<ul><li>![[Pasted image 20210607120349.png]]</li><li>Volume gradually increased; detection decision shown</li><li>Detection instability at critical source strength</li></ul></li><li>Selection in presence of 2 sources<ul><li>![[Pasted image 20210607121048.png]]</li></ul></li><li>1 source with reflecting surface on flank (robust estimation)<ul><li>![[Pasted image 20210607121201.png]]</li></ul></li><li>Tracking of moving source<ul><li>![[Pasted image 20210607121227.png]]</li></ul></li><li>To generate source-seeking motion<ul><li>induce attractor ins dyanmics of headin direction at location of snesory peak</li></ul></li><li>First shot formalism: treat peak as mean of sensory distribution (with sigmoid applied to it)<ul><li>Requires normalization</li><li>No peak -> computationally unstable</li><li>Bad</li></ul></li><li>Activation field must generate attractor if peak, no change if no peak<ul><li>use negative slope of dynamic contribution that erects attractor at peak location proportional to strength of peak</li><li>$\dot{\phi}=-
<a href=../../%5cphi-%5cpsi_%7bpeak%7d rel=noopener>\int g(u(\psi))d\psi</a>
$</li><li>$g$ - sigmoid</li><li>![[Pasted image 20210607123203.png]]</li><li>Substituting the expression of mean of $\psi$, normalized:</li><li>$\dot{\phi}=-[\int g(u(\psi))\phi d\psi-\int g(u(\psi))\psi d\psi]$</li><li>Normalization cancels out, no divide-by-zero problems</li><li>Activation field -> heading dynamics</li><li>Vote $-[\phi-\psi]$ by each field location with strength proportional to $g(u(\psi))$</li><li>Range limiting factor may be used, cf. [[Dynamic Field Theory#Obstacle Avoidance]]</li></ul></li><li>Two sources -> decision instability, stabilization by neural field</li><li>![[Pasted image 20210607123910.png]]<ul><li>Closer to left originally</li></ul></li><li>![[Pasted image 20210607123937.png]]<ul><li>Closer to right originally</li></ul></li><li>NOTE: Only vehicle coordinates matter here due to the nature of the equations<ul><li>Errors in $\phi$ and $\psi$ cancel out</li></ul></li><li>Limb movement based on motor plans<ul><li>![[Pasted image 20210607124157.png]]</li><li>Muscles produce exactly enough torque to compensate for external weight</li><li>Reflex loops stabilize torque output</li><li>Movement -> shifting equilibrium point by the descending command &lt;-> peaks setting attractors</li></ul></li></ul><hr><h4 id=obstacle-avoidance>Obstacle Avoidance</h4><ul><li>Potential field approach<ul><li>Effector -> attractor</li><li>Obstacles -> repellors</li></ul></li><li>Attractor dynamics approach<ul><li>System is always in or near attractor</li><li>Direction of obstacle $\psi_{obst}$ generates a repelling &lsquo;forcelet&rsquo;<ul><li>$\dot{\phi}=&mldr;+(\phi-\psi_{obst})exp[-\frac{(\phi-\psi_{obst})^2}{2\Delta^2}]$</li><li>![[Pasted image 20210607122213.png]]</li><li>Limited range</li><li>Two half-attractors</li></ul></li></ul></li><li>Describes human obstacle avoidance quite well too</li></ul><hr><h3 id=embodied-a-not-b>Embodied A Not B</h3><ul><li>Neural dynamics to control real body acting in the world</li><li>Video input</li><li>Color matching filter -> only one color activates</li><li>![[Pasted image 20210607144222.png]]</li><li>Same motor organization as phonotaxis vehicle<ul><li>Seeks yellow sources</li></ul></li><li>Added memory trace cf. [[Dynamic Field Theory#Memory Trace]]</li><li>![[Pasted image 20210607144420.png]]</li><li>Activation field and memory trace evolution:<ul><li>![[Pasted image 20210607144803.png]]</li><li>Boost at A due to specific cue, causes slight favoring later => peak</li><li>Activation field at this time:</li><li>![[Pasted image 20210607144932.png]]</li></ul></li><li>By the first B trial, significant memory of A => A-not-B error</li><li>Explanation for [[Dynamic Field Theory#Illustration DFT Model of Perseverative Reaching]]</li><li>Further experiments:</li><li>Obstacles in path to yellow target<ul><li><p>![[Pasted image 20210607145347.png]]</p></li><li><p>Left - without memory trace; Right - with memory trace</p></li><li><p>&lsquo;Young&rsquo; (dotted line) robot makes error</p><ul><li>unable to sustain peaks of activation</li></ul></li><li><p>&lsquo;Old&rsquo; (solid line) robot retains memory of target</p><ul><li>can sustain peaks of activation</li></ul></li><li><p>Capacity to sustain peaks important to reach goal under broader circumstances</p></li><li><p>With trace, both equivalent => peak stabilization</p></li><li><p>Memory trace- not as flexible as sustained activation</p></li><li><p>New peak can override previous target</p></li><li><p>Memory trace only forms from experience</p></li></ul></li><li>Why do younger ones rely on memory trace instead of sustained activation? [[Ideas+Thoughts]]<ul><li>Not really known, maybe one is more complex</li></ul></li></ul><hr><h1 id=integrating-lower-level-perception-action-with-higher-level-cognition>Integrating Lower-Level Perception-Action with Higher-Level Cognition</h1><ul><li>Does DFT scale up to higher-level cognition?</li><li>Large scale theory of visual cognition?</li></ul><h2 id=chapter-5-integration-and-selection-in-multidimensional-dynamic-fields>Chapter 5: Integration and Selection in Multidimensional Dynamic Fields</h2><ul><li>Multidimensional fields enable integration of colors and spatial positions<ul><li>Computationally costly</li><li>Full representation requires more neurons than brain has => implausible</li></ul></li><li>Fix: Selection<ul><li>System can selectively &ldquo;attend&rdquo; to particular aspects</li></ul></li></ul><h3 id=neurophysiology-of-higher-dimensional-representations>Neurophysiology of Higher Dimensional Representations</h3><ul><li>Neural populations for vision span 2D space of locations</li><li>&lsquo;Simple neurons&rsquo; - encode 2D location + orientation<ul><li>Form basis of shape and motion perception</li></ul></li><li>Similar maps exist for other visual features: color, spatial frequency, ocular dominance etc.<ul><li>All form representations over 2 space dims + 1 feature dim</li></ul></li><li>DF model -> activation over this 3d space</li><li>How do we know the functional dimensions?<ul><li>Vary particular perceptual dimensions and see which affect responses</li></ul></li><li>Multidimensional representations costlier than separate low dimensional repss</li></ul><h3 id=dynamics-of-higher-dimensional-fields>Dynamics of Higher Dimensional Fields</h3><h4 id=lateral-interactions-in-multidimensional-fields>Lateral Interactions in Multidimensional Fields</h4><ul><li><p>$\tau\dot{u}(x)=-u(x)+h+s(x)+ \int k(x-x')g(u(x'))dx'$</p></li><li><p>$x\in F$ - multidimensional field</p></li><li><p>$k(x,y)$ - difference of Gaussians (exc and inh)</p></li><li><p>$s(x,y)$ - Gaussian centered at input location</p></li><li><p>![[Pasted image 20210609123110.png]]</p></li><li><p>Similar behavior to 1D case (mostly)</p><ul><li>short range exc, long range inh, self stabilized peaks etc.</li></ul></li><li><p>Qualitatively different dimensions - different behavior</p><ul><li>eg. spatial distance, angular orientation</li></ul></li></ul><h3 id=real-time-integration-and-selection-in-dfs>Real-time Integration and Selection in DFs</h3><ul><li>1 space dim + 1 hue dim</li><li>![[Pasted image 20210609124314.png]]</li><li>Early visual cortex -> no global competition</li><li>Read-out -> integrate over the disregarded dimension + convolve with Gaussian kernel<ul><li>Input for 1D fields in figure</li><li>Loss of info -> location-color matching</li></ul></li><li>Integration not always useful -> spatial information needs to be conserved perfectly (selection) -> reaching behaviors</li><li>How to get integration adn selection<ul><li>easy fix - force fields to have only one peaks</li><li>can select one at a time to avoid binding errors</li></ul></li><li>![[Pasted image 20210609130118.png]]<ul><li>Projection from 1D -> 2D field</li></ul></li><li>![[Pasted image 20210609130452.png]]<ul><li>a - stimulation of 2D field, projects forward</li><li>b - global boost of 2D from 1D to form peak</li></ul></li><li>![[Pasted image 20210609130717.png]]<ul><li>Local top-down influence</li><li>&ldquo;Look for blue item&rdquo; by boosting</li><li>Strengthens corresponding peak</li><li>Similarly for &ldquo;Look for item on left&rdquo; etc.</li></ul></li><li>Disadvantage<ul><li>may be looking for red object, but none present</li><li>multiple object might match</li><li>depends on detailed settings in such cases</li></ul></li></ul><h3 id=integration--selection-in-autonomous-visual-exploratory-systems>Integration & Selection in Autonomous Visual Exploratory Systems</h3><ul><li>Close the loop on perception and action to create autonomous view of visual system</li><li>Human visual system<ul><li>rods cones distribution on retina uneven</li><li>concentrated at fovea (center)</li><li>saccade to bring attention to fovea</li></ul></li><li>biased competition model<ul><li>how does visual working memory (VWM) interact with attention and early visual processing; influence saccades</li></ul></li><li>Two stream hypothesis<ul><li>&lsquo;where&rsquo; and &lsquo;what&rsquo; streams of processing</li><li>spatial location vs. image features</li></ul></li><li>![[Pasted image 20210610110835.png]]<ul><li>c, e - attention fields</li><li>d - color memory field</li><li>f - saccade motor field</li></ul></li><li>Spatial field - WTA mechanism as before<ul><li>spatial attention</li><li>logarithmic scaling of spatial dimension -> area near fovea contributes more</li></ul></li><li>Saccade motor system -> strong local exc, global inh</li><li>Amplitude of saccade -> position of peak<ul><li>Neural integrator that integrates entire saccade field as inhibitor, to end saccade</li></ul></li></ul><h3 id=vwm--and-saccade-orienting-in-remote-distractor>VWM and Saccade Orienting in Remote Distractor</h3><ul><li>![[Pasted image 20210610112140.png]]<ul><li>Memorize color (blue box)</li><li>Perform saccade to red spot (bigger, farther), avoid green spot (smaller, closer distractor)</li><li>Test memory of color by identifying box</li><li>Some trials had different saccade dots with color matches as shown on right</li></ul></li><li>![[Pasted image 20210610112528.png]]<ul><li>Even though distractor was always on wrong side, errors still made when color matched</li><li>When distractor color matched, ~50% error</li><li>When target color matched, ~0% error</li></ul></li><li>Simulations of this experiment<ul><li>![[Pasted image 20210610113207.png]]</li><li>Distractor color matching strengthens extant peak in color memory field</li><li>Causes back projection to sensory field and then spatial field, that makes it peak at the distractor position</li><li>Wrong saccade</li></ul></li><li>Activation bimodal in all conditions</li></ul><h3 id=function-and-fallibility-of-visual-feature-integration>Function and Fallibility of Visual Feature Integration</h3><ul><li>Should this framework be expanded to higher dimensions?<ul><li>Not really, since the visual cortex doesn&rsquo;t do this</li></ul></li><li>Brain has separate populations for each dimensions -> less computationally expensive</li><li>But then how do we see objects as wholes instead of separate features -> binding problem</li><li>Expanded biased competition model -> add more fields and achieve same functionality without dramatic increase in demands</li><li>![[Pasted image 20210610115021.png]]<ul><li>top b, c, d - color field</li><li>bottom b, c, d - shape field</li><li>b - visual sensory fields</li><li>c - feature attention fields</li><li>d - feature memory fields</li><li>e - spatial attention field</li><li>f - spatial read-out field (formerly saccade motor field)</li></ul></li><li>Only one extra set of fields here but can have more</li><li>Space-color (S-C) fields and space-shape (S-S) fields</li><li>Both visual sensory fields are coupled with spatial attention field -> coupled to each other indirectly<ul><li>(b&lt;->e&lt;->b)</li></ul></li><li>Single multifeature item -> peak in S-C field + peak in S-S field</li><li>Multiple items -> good old which-is-which problem<ul><li>Forcing selection (single peak) helps here too</li><li>Single peak in both fields must correspond to same item</li><li>Coherent representation</li><li>Need mechanism to determine which is chosen</li></ul></li><li>Color attention and shape retrieval task:<ul><li>Multiple objects (letters) in different colors shown</li><li>Asked to say which had which color: &ldquo;which letter was in red&rdquo;</li></ul></li><li>Model adjustments:<ul><li>Cue item presented at start, having the required feature (color) -> peak in memory field</li><li>Read-out field -> maintain single peak (spatial attention)</li></ul></li><li>Simulation of model:<ul><li>![[Pasted image 20210610122538.png]]</li><li>a - cue item presented (not shown in figure)</li><li>b - color memory peak at one value corresponding to cue item -> ridge in S-C field -> peak in spatial attention field</li><li>c - S-S peak of target item prevails</li><li>d - illusory conjunction due to a nearby distractor enhanced too much by ridge; location response in between the two letters</li><li>With location cue, independent selection of shape and color observed in experiment</li><li>With color cue, dependent selection of shape and location</li><li>After location selected, doesn&rsquo;t matter how it was arrived at, for the other one-of-two decisions to be made</li></ul></li><li>Failure of model -> precisely in the same way that humans fail<ul><li>Feature errors (unpresented features reported as being seen)</li><li>Illusory conjunctions (red X + green T -> green X, etc.)<ul><li>Seen above, ridge movement due to reciprocal coupling</li><li>Probability higher for smaller inter-item distance</li></ul></li><li>Another IC experiment - participants shown multiple letters; one always green; asked to pick location of green O even when there was none; picked average spatial location of green letter and O<ul><li>Similar behavior found in model</li></ul></li><li>2 causes for ICs - spatial proximity and feature similarity -> influence each other, elevating IC probability</li></ul></li><li>Location Uncertainty Theory<ul><li>Uncertainty of position in feature registration phase causes errors</li><li>Not needed in this model; ICs generated at attention mechanism (feature integration) level</li></ul></li></ul><hr><h2 id=chapter-6-integrating-perception-and-working-memory-in-a-three-layer-dynamic-field-model>Chapter 6: Integrating Perception and Working Memory in a Three-Layer Dynamic Field Model</h2><ul><li>Spatial recall and change detection</li><li>![[Pasted image 20210611135831.png]]</li><li>Common feature- maintain stable state<ul><li>spatial reference frame and comparison</li></ul></li><li>Integration of perception and working memory</li></ul><h3 id=integrating-perceptual-and-memory-processes-in-3-layer-nf-architecture>integrating perceptual and memory processes in 3-layer NF architecture</h3><ul><li>3-layer field</li><li>![[Pasted image 20210611140501.png]]</li><li>contrast field $CON(u)$</li><li>working memory field $WM(w)$</li><li>inh field $Inhib(v)$</li><li>WM to CON only through INH</li><li>CON direct input</li></ul><h3 id=spatial-recall-biases>Spatial recall biases</h3><ul><li>Repelling of WM peak away from midline peak in CON<ul><li>angular error</li><li>varies across trials</li></ul></li><li>Complex pattern of drift and variability</li></ul><h3 id=visual-change-detection>Visual Change Detection</h3><ul><li>![[Pasted image 20210611141709.png]]<ul><li>left - no-change test set</li><li>right - change test set</li><li>encoding, maintenance over delay, generation of response, decision response</li></ul></li><li>Peaks below baseline after inputs removed, in CON</li><li>peaks remain in WM</li><li>Excitatory layers of all 3 coupled to accumulator to generate decision</li></ul><h3 id=behavioral-signatures-of-the-3-layers>Behavioral Signatures of the 3 Layers</h3><ul><li>How to use model to address behavioral phenomena</li></ul><h4 id=encoding>Encoding</h4><ul><li>Rate of encoding in WM increases as no. of items</li><li>![[Pasted image 20210611154558.png]]<ul><li>set size</li></ul></li></ul><h4 id=maintenance>Maintenance</h4><ul><li>Midline repulsion of peaks<ul><li>Strength of midline peak varied in experiment by marking / not marking</li></ul></li><li>Predictions<ul><li>toward axis -> better discrimination</li><li>near axis -> enhanced discrimination</li><li>salience of axis -> more enhancement</li></ul></li><li>![[Pasted image 20210611155018.png]]<ul><li>Mistake when second stimulus presented away from axis (in direction of drift)</li></ul></li><li>Other two predictions also verified in experiments</li><li>Peak repulsion -> strong inhibition -> similar items held nearby recalled to be more different than they really are</li><li>![[Pasted image 20210611155454.png]]<ul><li>Color wheel test -> two similar colors recalled in opposite directions</li></ul></li></ul><h4 id=comparison>Comparison</h4><ul><li>Change detection should be enhanced with multiple similar items vs. few unique items<ul><li>Confirmed in experiment</li><li>![[Pasted image 20210611160144.png]]</li></ul></li><li>Capacity limited model<ul><li>Inhibition overwhelms beyond a point</li></ul></li></ul><h4 id=decision>Decision</h4><ul><li>Limitations of old single threshold (same / different) model<ul><li>No active decision in &lsquo;different&rsquo; trial</li><li>Not neurally realistic -> relies on absence of activation</li></ul></li><li>Both fixed here (two threshold variables, active decisions)</li><li>Faster response on &lsquo;same&rsquo; trials</li></ul><h3 id=comparison-with-other-models>Comparison with Other Models</h3><ul><li>Category Adjustment Model<ul><li>Fine location + category : encoding</li><li>Less broad in explanation scope than DFT 3-layer</li></ul></li><li>Fixed resolution slots model<ul><li>WM stores info in limited discrete slows</li><li>When set size exceeds slot count, performance degrades</li></ul></li><li>Another similar: flexible allocation of WM space</li><li>DFT better than these two:<ul><li>Metric effects can be explained</li><li>Variety of tasks</li></ul></li></ul><hr><h2 id=chapter-7-sensory-motor-and-cognitive-transformation>Chapter 7: Sensory-Motor and Cognitive Transformation</h2><ul><li>Reference Frames</li></ul><h3 id=role-of-reference-frames>Role of Reference Frames</h3><ul><li>![[Pasted image 20210621150309.png]]</li><li>Representation by population in one frame is consistent -> inconsistent in others moved relative to this</li><li>Reference frame of neural population -> independent of anatomical (retinotopic) organization of individual neurons</li></ul><h3 id=reference-frame-transformations---gain-modulation>Reference Frame Transformations - Gain Modulation</h3><ul><li>Variable shift parameterized by current position of eyes</li><li>Gain-modulated neurons</li><li>Fixation task while visual stimuli presented<ul><li>![[Pasted image 20210621163439.png]]</li></ul></li><li>Firing pattern consistent with retinocentric representation</li><li>Overall strength depended on fixation point (gaze), though</li><li>![[Pasted image 20210621163556.png]]<ul><li>Typically linear dependence on gaze direction</li></ul></li></ul><h3 id=reference-frame-transformations---df-model>Reference Frame Transformations - DF Model</h3><ul><li>retinocentric -> body centered</li><li>need to perform angular addition with neural population</li><li>![[Pasted image 20210622155040.png]]<ul><li>all points on diagonal correspond to same real-world point</li></ul></li><li>retinal position + gaze direction -> body-centered location</li></ul><h3 id=extensions-of-the-basic-mechanism>Extensions of the Basic Mechanism</h3><ul><li>![[Pasted image 20210622155051.png]]</li><li>Need support for multiple peaks</li><li>Reversal of projection direction -> memory of visual location</li><li>![[Pasted image 20210622155338.png]]</li><li>Reference Frame Alignment problem:<ul><li>![[Pasted image 20210622155445.png]]</li><li>![[Pasted image 20210622155604.png]]</li><li>Strongest input location will determine correct shift</li><li>Symmetric arrangement of boxes -> impossible to determine correct orientation<ul><li>Single gaze peak makes sense</li></ul></li></ul></li></ul><h3 id=multidirectional-transformations>Multidirectional Transformations</h3><ul><li>Two-way connections between all 3 fields</li><li>Strength of activation determines direction of signal flow</li><li>![[Pasted image 20210622161222.png]]</li><li>Essentially one large dynamical system</li></ul><hr><h2 id=chapter-8-integrating-what-and-where>Chapter 8: Integrating What and Where</h2></article><hr><div class=page-end><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script>const index={backlinks:{"/Books/Books":[{source:"/",target:"/Books/Books",text:"Books"}],"/Books/Novacene":[{source:"/",target:"/Books/Novacene",text:"Novacene"}],"/Books/Skyward_Series":[{source:"/",target:"/Books/Skyward_Series",text:"Skyward"}],"/\\phi-\\psi_{peak}":[{source:"/Books/Dynamic Field Theory",target:"/\\phi-\\psi_{peak}",text:"\\int g(u(\\psi))d\\psi"}],"/moc/GM":[{source:"/",target:"/moc/GM",text:"Test Note"}],"/moc/directory":[{source:"/",target:"/moc/directory",text:"Directory"}],"/moc/showcase":[{source:"/moc/directory",target:"/moc/showcase",text:"community digital gardens"}],"/notes/config":[{source:"/moc/directory",target:"/notes/config",text:"Customizing and Styling Quartz"},{source:"/notes/editing",target:"/notes/config",text:"A link to the config page"},{source:"/notes/hosting",target:"/notes/config",text:"Customizing Quarts"},{source:"/notes/troubleshooting",target:"/notes/config",text:"customization guide"}],"/notes/editing":[{source:"/notes/setup",target:"/notes/editing",text:"Editing Notes in Quartz"},{source:"/notes/troubleshooting",target:"/notes/editing",text:"local editing"}],"/notes/hosting":[{source:"/moc/directory",target:"/notes/hosting",text:"Hosting Quartz online!"},{source:"/notes/editing",target:"/notes/hosting",text:"Hosting Quartz online!"},{source:"/notes/troubleshooting",target:"/notes/hosting",text:"the hosting guide"},{source:"/notes/troubleshooting",target:"/notes/hosting",text:"hosting"}],"/notes/ignore-notes":[{source:"/notes/editing",target:"/notes/ignore-notes",text:"Excluding pages from being published"},{source:"/notes/troubleshooting",target:"/notes/ignore-notes",text:"excluding pages from being published"}],"/notes/obsidian":[{source:"/moc/directory",target:"/notes/obsidian",text:"Linking with an Obsidian Vault"},{source:"/notes/editing",target:"/notes/obsidian",text:"How to link your Obsidian Vault"},{source:"/notes/troubleshooting",target:"/notes/obsidian",text:"Obsidian"}],"/notes/preview-changes":[{source:"/notes/editing",target:"/notes/preview-changes",text:"Preview Quartz Changes"}],"/notes/setup":[{source:"/moc/directory",target:"/notes/setup",text:"Setup your own digital garden using Quartz"}],"/notes/troubleshooting":[{source:"/moc/directory",target:"/notes/troubleshooting",text:"Troubleshooting and FAQ"},{source:"/notes/config",target:"/notes/troubleshooting",text:"FAQ and Troubleshooting guide"},{source:"/notes/editing",target:"/notes/troubleshooting",text:"FAQ and Troubleshooting guide"},{source:"/notes/hosting",target:"/notes/troubleshooting",text:"FAQ and Troubleshooting guide"},{source:"/notes/setup",target:"/notes/troubleshooting",text:"FAQ and Troubleshooting guide"}]},links:{"/":[{source:"/",target:"/Books/Skyward_Series",text:"Skyward"},{source:"/",target:"/Books/Books",text:"Books"},{source:"/",target:"/moc/directory",text:"Directory"},{source:"/",target:"/moc/GM",text:"Test Note"},{source:"/",target:"/Books/Novacene",text:"Novacene"}],"/Books/Dynamic Field Theory":[{source:"/Books/Dynamic Field Theory",target:"/\\phi-\\psi_{peak}",text:"\\int g(u(\\psi))d\\psi"}],"/moc/directory":[{source:"/moc/directory",target:"/moc/showcase",text:"community digital gardens"},{source:"/moc/directory",target:"/notes/troubleshooting",text:"Troubleshooting and FAQ"},{source:"/moc/directory",target:"/notes/setup",text:"Setup your own digital garden using Quartz"},{source:"/moc/directory",target:"/notes/obsidian",text:"Linking with an Obsidian Vault"},{source:"/moc/directory",target:"/notes/config",text:"Customizing and Styling Quartz"},{source:"/moc/directory",target:"/notes/hosting",text:"Hosting Quartz online!"}],"/notes/config":[{source:"/notes/config",target:"/notes/troubleshooting",text:"FAQ and Troubleshooting guide"}],"/notes/editing":[{source:"/notes/editing",target:"/notes/obsidian",text:"How to link your Obsidian Vault"},{source:"/notes/editing",target:"/notes/ignore-notes",text:"Excluding pages from being published"},{source:"/notes/editing",target:"/notes/config",text:"A link to the config page"},{source:"/notes/editing",target:"/notes/preview-changes",text:"Preview Quartz Changes"},{source:"/notes/editing",target:"/notes/hosting",text:"Hosting Quartz online!"},{source:"/notes/editing",target:"/notes/troubleshooting",text:"FAQ and Troubleshooting guide"}],"/notes/hosting":[{source:"/notes/hosting",target:"/notes/config",text:"Customizing Quarts"},{source:"/notes/hosting",target:"/notes/troubleshooting",text:"FAQ and Troubleshooting guide"}],"/notes/setup":[{source:"/notes/setup",target:"/notes/editing",text:"Editing Notes in Quartz"},{source:"/notes/setup",target:"/notes/troubleshooting",text:"FAQ and Troubleshooting guide"}],"/notes/troubleshooting":[{source:"/notes/troubleshooting",target:"/notes/hosting",text:"the hosting guide"},{source:"/notes/troubleshooting",target:"/notes/editing",text:"local editing"},{source:"/notes/troubleshooting",target:"/notes/ignore-notes",text:"excluding pages from being published"},{source:"/notes/troubleshooting",target:"/notes/hosting",text:"hosting"},{source:"/notes/troubleshooting",target:"/notes/obsidian",text:"Obsidian"},{source:"/notes/troubleshooting",target:"/notes/config",text:"customization guide"}]}},links=[{source:"/Books/Dynamic Field Theory",target:"/\\phi-\\psi_{peak}",text:"\\int g(u(\\psi))d\\psi"},{source:"/",target:"/Books/Skyward_Series",text:"Skyward"},{source:"/",target:"/Books/Books",text:"Books"},{source:"/",target:"/moc/directory",text:"Directory"},{source:"/",target:"/moc/GM",text:"Test Note"},{source:"/",target:"/Books/Novacene",text:"Novacene"},{source:"/moc/directory",target:"/moc/showcase",text:"community digital gardens"},{source:"/moc/directory",target:"/notes/troubleshooting",text:"Troubleshooting and FAQ"},{source:"/moc/directory",target:"/notes/setup",text:"Setup your own digital garden using Quartz"},{source:"/moc/directory",target:"/notes/obsidian",text:"Linking with an Obsidian Vault"},{source:"/moc/directory",target:"/notes/config",text:"Customizing and Styling Quartz"},{source:"/moc/directory",target:"/notes/hosting",text:"Hosting Quartz online!"},{source:"/notes/config",target:"/notes/troubleshooting",text:"FAQ and Troubleshooting guide"},{source:"/notes/editing",target:"/notes/obsidian",text:"How to link your Obsidian Vault"},{source:"/notes/editing",target:"/notes/ignore-notes",text:"Excluding pages from being published"},{source:"/notes/editing",target:"/notes/config",text:"A link to the config page"},{source:"/notes/editing",target:"/notes/preview-changes",text:"Preview Quartz Changes"},{source:"/notes/editing",target:"/notes/hosting",text:"Hosting Quartz online!"},{source:"/notes/editing",target:"/notes/troubleshooting",text:"FAQ and Troubleshooting guide"},{source:"/notes/hosting",target:"/notes/config",text:"Customizing Quarts"},{source:"/notes/hosting",target:"/notes/troubleshooting",text:"FAQ and Troubleshooting guide"},{source:"/notes/setup",target:"/notes/editing",text:"Editing Notes in Quartz"},{source:"/notes/setup",target:"/notes/troubleshooting",text:"FAQ and Troubleshooting guide"},{source:"/notes/troubleshooting",target:"/notes/hosting",text:"the hosting guide"},{source:"/notes/troubleshooting",target:"/notes/editing",text:"local editing"},{source:"/notes/troubleshooting",target:"/notes/ignore-notes",text:"excluding pages from being published"},{source:"/notes/troubleshooting",target:"/notes/hosting",text:"hosting"},{source:"/notes/troubleshooting",target:"/notes/obsidian",text:"Obsidian"},{source:"/notes/troubleshooting",target:"/notes/config",text:"customization guide"}],curPage="/Books/Dynamic-Field-Theory",pathColors=[{"/moc":"#4388cc"}],parseIdsFromLinks=a=>[...new Set(a.flatMap(a=>[a.source,a.target]))],data={nodes:parseIdsFromLinks(links).map(a=>({id:a})),links},color=a=>{if(a.id===curPage||a.id==="/"&&curPage==="")return"var(--g-node-active)";for(const b of pathColors){const c=Object.keys(b)[0],d=b[c];if(a.id.startsWith(c))return d}return"var(--g-node)"},drag=c=>{function d(b,a){b.active||c.alphaTarget(1).restart(),a.fx=a.x,a.fy=a.y}function e(a,b){b.fx=a.x,b.fy=a.y}function f(b,a){b.active||c.alphaTarget(0),a.fx=null,a.fy=null}const a=!0,b=()=>{};return d3.drag().on("start",a?d:b).on("drag",a?e:b).on("end",a?f:b)},height=250,width=document.getElementById("graph-container").offsetWidth,simulation=d3.forceSimulation(data.nodes).force("charge",d3.forceManyBody().strength(-20)).force("link",d3.forceLink(data.links).id(a=>a.id)).force("center",d3.forceCenter()),svg=d3.select('#graph-container').append('svg').attr('width',width).attr('height',height).attr("viewBox",[-width/2,-height/2,width,height]),enableLegend=!1;if(enableLegend){const a=[{Current:"var(--g-node-active)"},{Note:"var(--g-node)"},...pathColors];a.forEach((a,b)=>{const c=Object.keys(a)[0],d=a[c];svg.append("circle").attr("cx",-width/2+20).attr("cy",height/2-30*(b+1)).attr("r",6).style("fill",d),svg.append("text").attr("x",-width/2+40).attr("y",height/2-30*(b+1)).text(c).style("font-size","15px").attr("alignment-baseline","middle")})}const link=svg.append("g").selectAll("line").data(data.links).join("line").attr("class","link").attr("stroke","var(--g-link)").attr("stroke-width",2).attr("data-source",a=>a.source.id).attr("data-target",a=>a.target.id),graphNode=svg.append("g").selectAll("g").data(data.nodes).enter().append("g"),node=graphNode.append("circle").attr("class","node").attr("id",a=>a.id).attr("r",a=>{const b=index.links[a.id]?.length||0,c=index.backlinks[a.id]?.length||0;return 3+(b+c)/4}).attr("fill",color).style("cursor","pointer").on("click",(b,a)=>{window.location.href="https://quartz.jzhao.xyz/"+a.id}).on("mouseover",function(f,a){d3.selectAll(".node").transition().duration(100).attr("fill","var(--g-node-inactive)");const c=parseIdsFromLinks([...index.links[a.id]||[],...index.backlinks[a.id]||[]]),d=d3.selectAll(".node").filter(a=>c.includes(a.id)),b=a.id,e=d3.selectAll(".link").filter(a=>a.source.id===b||a.target.id===b);d.transition().duration(200).attr("fill",color),e.transition().duration(200).attr("stroke","var(--g-link-active)"),d3.select(this.parentNode).select("text").raise().transition().duration(200).style("opacity",1)}).on("mouseleave",function(d,b){d3.selectAll(".node").transition().duration(200).attr("fill",color);const a=b.id,c=d3.selectAll(".link").filter(b=>b.source.id===a||b.target.id===a);c.transition().duration(200).attr("stroke","var(--g-link)"),d3.select(this.parentNode).select("text").transition().duration(200).style("opacity",0)}).call(drag(simulation)),labels=graphNode.append("text").attr("dx",12).attr("dy",".35em").text(a=>a.id).style("opacity",0).style("pointer-events","none").call(drag(simulation)),enableZoom=!0;enableZoom&&svg.call(d3.zoom().extent([[0,0],[width,height]]).scaleExtent([.25,4]).on("zoom",({transform:a})=>{link.attr("transform",a),node.attr("transform",a),labels.attr("transform",a)})),simulation.on("tick",()=>{link.attr("x1",a=>a.source.x).attr("y1",a=>a.source.y).attr("x2",a=>a.target.x).attr("y2",a=>a.target.y),node.attr("cx",a=>a.x).attr("cy",a=>a.y),labels.attr("x",a=>a.x).attr("y",a=>a.y)})</script></div></div><div id=contact_buttons><footer><p>Made by Jacky Zhao using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, © 2021</p><a href=../../>Home</a>
<a href=https://twitter.com/_jzhao>Twitter</a><a href=https://github.com/jackyzha0>Github</a></footer></div></div><script>const toggleSwitch=document.querySelector('#darkmode-toggle'),userPref=window.matchMedia('(prefers-color-scheme: light)').matches?'light':'dark',currentTheme=localStorage.getItem('theme')??userPref;currentTheme&&(document.documentElement.setAttribute('saved-theme',currentTheme),currentTheme==='dark'&&(toggleSwitch.checked=!0));const switchTheme=a=>{a.target.checked?(document.documentElement.setAttribute('saved-theme','dark'),localStorage.setItem('theme','dark')):(document.documentElement.setAttribute('saved-theme','light'),localStorage.setItem('theme','light'))};toggleSwitch.addEventListener('change',switchTheme,!1)</script></body></html>